<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Auto Neutralization of Sensitive Text</title>

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500&display=swap" rel="stylesheet">

    <!-- Bootstrap CDN v5.1.3 -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">

    <!-- Custom CSS -->
    <link href="./assets/stylesheets/index.css" rel="stylesheet">

</head>

<body>
    <header>
        <div class="header_container">
            <div class="container h-100">
                <div class="row justify-content-center h-100 align-items-center">
                    <div class="col-md-7 text-center">
                        <img src="./assets/images/header/header_eye.png" height="150" alt="">
                        <p class="mt-3 mb-5 pb-5">
                            This tool contains an intelligent algorithm that automatically neutralizes sensitive text on
                            the webspace using a plugin that is a combination of NLP and Web Development.
                        </p>
                        <br>
                        <hr class="mt-5" style="border-top: 1.5px solid #111111;">
                        <a class="mt-3">
                            Use Plugin
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <section class="container">
        <div class="row">
            <div class="col-lg-6 mb-5">
                <h2>
                    Problem Statement
                </h2>
                <h4>
                    Auto Neutralization of Racist and Sexist web pages.
                </h4>
                <p>
                    At this point on the internet, people from all over the world are interacting with each other. In
                    order for marginalized
                    communities to not undergo harassment we need to have a robust and general solution. This solution
                    will only work if
                    both the parties win.
                </p>
            </div>
            <div class="col-lg-6 mb-5"></div>
            <div class="col-lg-6 mb-5">
                <h2>
                    Relevance
                </h2>
                <p>
                <ul>
                    <li>
                        This project is a combination of NLP and Web Development. It perfectly combines Machine Learning
                        and
                        General Development
                        thus is relevant to computer science.
                    </li>
                    <li>
                        Moreover, our team has taken subjects like NLP, ML and Big Data. Thus it combines previously
                        learnt
                        methods to newer
                        ones.
                    </li>
                </ul>
                </p>
            </div>
            <div class="col-lg-6 mb-5"></div>
            <div class="col-lg-6 mb-5">
                <h2>
                    Proposed Solution
                </h2>
                <p>
                    We plan to have a generalized Machine Learning model which can detect and neutralize racist/sexist
                    content. Our solution
                    will have three sections.
                </p>
            </div>
            <div class="col-lg-6 mb-5"></div>
            <div class="col-lg-6 mb-5">
                <h2>
                    Parts of the Solution.
                </h2>
                <p>
                <ul>
                    <li>
                        Firstly, we will have a Browser Extension available for all the browsers which will take note of
                        the websites you see
                        and scrape the content of the websites.
                    </li>
                    <li>
                        Secondly, we will have an ML model which will detect racist and sexist portions of the text and
                        neutralize it. That is,
                        it will remove offensive content and paraphrase the rest using the remaining key words while
                        retaining the original
                        meaning.
                    </li>
                    <li>
                        Lastly, we will give the user the right to choose the degree of exposure. The user can choose
                        from the following three
                        options:
                        <ol type="A">
                            <li>
                                Completely view the page with original text. The sensitive text is detected and then
                                reported automatically without user
                                intervention.
                            </li>
                            <li>
                                With the page with changed text but the user can still see highlighted portions of the
                                website, where upon hovering, the
                                user will be able to see the original text.
                            </li>
                            <li>
                                The user will be shown a completely screened and filtered page and will not know what
                                text was changed, ensuring
                                consensual ignorance.
                            </li>
                        </ol>
                    </li>
                </ul>
                </p>
            </div>
            <div class="col-lg-6 mb-5"></div>
            <div class="col-lg-6 mb-5">
                <h2>
                    Additional Scope.
                </h2>
                <p>
                    Based on threat level of the text, we will be able to auto-report the site/original poster. Or we
                    will simply choose to
                    neutralize the text to suit the user's taste.
                    <br>
                    <strong>
                        Eg:
                    </strong>
                    "I will kill this faggot." counts as a threat.
                    <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"This faggot doesn't know anything." is flagged as insensitive
                    and not a
                    threat. The
                    text will be neutralized.
                </p>
            </div>
            <div class="col-lg-6 mb-5"></div>
            <div class="col-lg-6 mb-5">
                <h2>
                    ML Model
                </h2>
                <h4>
                    XLnet
                </h4>
                <p>
                    Text classification is a key function required for the detection of racist and sexist text. For
                    this, we have scrapped
                    data from over 20 sources to collate one consolidated dataset which covers over 30,000 rows of
                    sexist text, annotated
                    and classified.
                    <br>
                    XLnet is an extension of the Transformer-XL model pre-trained using an autoregressive method to
                    learn bidirectional
                    contexts by maximizing the expected likelihood over all permutations of the input sequence
                    factorization order. In
                    simple words - XLNet is a generalized autoregressive model. XLNet uses Transformer XL as a feature
                    extracting
                    architecture, which is better than BERTâ€™s Transformer since Transformer XL added recurrence to the
                    Transformer. Which
                    can make the XLNet has a deeper understanding of the language context. XLnet has outperformed BERT,
                    T5, DistilBERT in
                    the text classification domain.
                </p>
                <br><br>
                <h4>
                    Paraphrasing
                </h4>
                <p>
                    For the purpose of paraphrasing, we have two main frameworks in mind:
                <h5>
                    Parrot
                </h5>
                the 3 key metrics that measure the quality of paraphrases are:
                <ol>
                    <li>
                        <strong>
                            Adequacy
                        </strong>
                        (Is the meaning preserved adequately?)
                    </li>
                    <li>
                        <strong>
                            Fluency
                        </strong>
                        (Is the paraphrase fluent English?)
                    </li>
                    <li>
                        <strong>
                            Diversity
                        </strong>
                        (Lexical / Phrasal / Syntactical) (How much has the paraphrase changed the original sentence?)
                    </li>
                </ol>
                Parrot offers knobs to control Adequacy, Fluency, and Diversity as per our needs.
                <br>
                <br>
                <h5>
                    Pegasus
                </h5>
                <ul>
                    <li>
                        The model will derive paraphrases from an input sentence, and we will also be comparing how it
                        is
                        different from the
                        input sentence.
                    </li>
                    <li>
                        The PEGASUS model's pre-training task is very similar to summarization, i.e. important sentences
                        are
                        removed and masked
                        from an input document and are later generated together as one output sequence from the
                        remaining
                        sentences, which is
                        fairly similar to a summary.
                    </li>
                    <li>
                        In PEGASUS, several whole sentences are removed from documents during pre-training, and the
                        model is
                        tasked with
                        recovering them. The Input for such pre-training is a document with missing sentences, while the
                        output
                        consists of the
                        missing sentences being concatenated together.
                    </li>
                    <li>
                        The advantage of this self-supervision is that you can create as many examples as there are
                        documents
                        without any human
                        intervention, which often becomes a bottleneck problem in purely supervised systems.
                    </li>
                </ul>
                </p>
            </div>
            <div class="col-lg-6 mb-5">
                <img src="./assets/images/ML/ml_workflow.jpeg" class="w-100" alt="">
            </div>
        </div>
    </section>

    <footer>

    </footer>


    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
        crossorigin="anonymous"></script>
</body>

</html>